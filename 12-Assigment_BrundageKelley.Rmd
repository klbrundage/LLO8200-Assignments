---
title: "12 - Assignment - Kelley Brundage"
author: "Kelley Brundage"
date: "7/23/2019"
Github: "https://github.com/klbrundage/LLO8200-Assignments"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,warning=FALSE,results='hide',include=TRUE,messages=FALSE)

##We always start with a standard set of setup commands by loading the correct libraries. We will continue to work with our existing libraries and will add 'caret' in order to evaluate the perforance of a classifier.

##Load libraries in order to successfully run the code below - the suppressMessages coding will stop the install.packages information, etc.. from coming up in the Console and showing you what has run.

suppressMessages(library(caret)) #Misc functions for training and plotting classification and regression models.
suppressMessages(library(dplyr)) #able to select, filter, organize, and manipulate data stored within an R data frame
suppressMessages(library(evaluate)) #Parsing and Evaluation Tools that Provide More Details than the Default
suppressMessages(library(flexclust))
suppressMessages(library(forcats)) #Tools for Working with Categorical Variables (Factors)
suppressMessages(library(formatR)) #Provides a function tidy_source() to format R source code.
suppressMessages(library(ggplot2)) #A system for 'declaratively' creating graphics, based on "The Grammar of Graphics".
suppressMessages(library(haven)) #Import foreign statistical formats into R via the embedded 'ReadStat' C library
suppressMessages(library(LICORS))
suppressMessages(library(knitr))#General-Purpose Package for Dynamic Report Generation in R 
  opts_chunk$set(comment = NA)
  def_hook <- knit_hooks$get("output")
  knit_hooks$set(output = function(x, options)
    {out <- def_hook(x, options)
    return(paste("\\begin{framed}\\begin{verbatim}", x, "\\end{verbatim}\\end{framed}",
                 collapse = "\n"))})

suppressMessages(library(lubridate)) #Functions to work with date-times and time-spans: fast and user friendly parsing of date-time data, extraction and updating of components of a date-time
suppressMessages(library(ModelMetrics)) #Collection of metrics for evaluating models written in C++ using 'Rcpp'.
suppressMessages(library(modelr)) #Functions for modelling that help you seamlessly integrate modelling into a pipeline of data manipulation and visualisation.
suppressMessages(library(pander))#provide a minimal and easy tool for rendering R objects
  panderOptions('table.style', "multiline")
  panderOptions('table.alignment.default',function(df)ifelse(sapply(as.data.frame(df),
                                                            is.numeric),'right','left'))

suppressMessages(library(readxl)) #reads in Excel Files
suppressMessages(library(rvest)) #scraping websites
suppressMessages(library(stats))
suppressMessages(library(tibble)) #Provides a 'tbl_df' class (the 'tibble') that provides stricter checking and better formatting than the traditional data frame.
suppressMessages(library(tidyverse)) #set of packages that work in harmony because they share common data representations and 'API' design
suppressMessages(library(tictoc))#his package provides the timing functions 'tic' and 'toc' that can be nested. One can record all timings while a complex script is running, and examine the values later.

##Define My PDF setup
#This code does not show in the final document but will assist with definining the margin cutoff point and wraps the text to the next line.

knitr::opts_chunk$set(fig.path = "Figs/", results='hide', tidy.opts=list(width.cutoff=60)) 
  my_pdf = function(file,width,height)
  {pdf(file, width=width, height=height,pointsize=12)}

```

# Question #1:
**Download the student evaluation dataset from the website.**

```{r Student evaluation dataset}

stdevgen <- read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/00262/turkiye-student-evaluation_generic.csv")

save(stdevgen, file = "turkiye-student-evaluation_generic.csv") #save as excel file name cwurData.xlsx

##2nd std evaluation file
stdevrspec <- read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/00262/turkiye-student-evaluation_R_Specific.csv")

save(stdevrspec, file = "turkiye-student-evaluation_R_Specific.csv")

```


# Question #2:
**Select a set of 10 related variables that you think might serve as the basis for clustering.**

My 10 related variables are listed below and the explanation of each variable can be found at the following website: http://archive.ics.uci.edu/ml/datasets/turkiye+student+evaluation


    instr: Instructor's identifier; values taken from {1,2,3} 
    class: Course code (descriptor); values taken from {1-13} 
    repeat: Number of times the student is taking this course; values taken from {0,1,2,3,...} 
    attendance: Code of the level of attendance; values from {0, 1, 2, 3, 4} 
    difficulty: Level of difficulty of the course as perceived by the student; values taken from {1,2,3,4,5} 
    Q6: The textbook and other courses resources were sufficient and up to date.	
    Q7: The course allowed field work, applications, laboratory, discussion and other studies. . 
    Q13: knowledge The Instructor's knowledge was relevant and up to date. 
    Q14: prepared The Instructor came prepared for classes. 
    Q19: The Instructor made effective use of class hours.  
    Q21: positive The Instructor demonstrated a positive approach to students. 
    Q22: respect The Instructor was open and respectful of the views of students about the course. 
    Q23: encourage The Instructor encouraged participation in the course. 
    Q25: available The Instructor responded to questions about the course inside and outside of the course. 
    Q27: solutions The Instructor provided solutions to exams and discussed them with students. 
    

    Note: Q1-Q28 are all Likert-type, meaning that the values are taken from {1,2,3,4,5}

```{r Keep Ten Related Variables}
##Remove unwanted columns

std1 <- stdevgen[ ,-(c(6:10,13:17,20:22,24,28,30,32))]
View(std1)

```


# Question #3: 
**Run the clustering algorithm kmeanspp to identify 3 clusters.**

```{r Kmeans clustering algorithm, results="asis"}
##Kmeans plus plus - 3 groups, start in a random spot, run 1,000 times over 50 iterations.  Should get the same numbers but not in the same order.  Should group the same points from the data just may not be in the same grouping as the first run.

kc1 <- kmeanspp(std1,k=3,start="random",iter.max=1000,nstart=50)

pander(table(kc1$cluster))
```

# Question #4:
**Summarize the clusters using the variables you selected.**

```{r Sum Groups by Cluster, results="asis"}
#Summarize groups by cluster

sum1 <- std1%>%
  group_by(kc1$cluster)%>%
  summarize_all(funs(mean),na.rm=TRUE)
  #summarize all of the variables - function is the mean and remove any missing data

pander(sum1)
```

```{r Gather Cluster Data, results="asis"}
##Now we'll `gather` everything, so that we have just two variables: the proportion (as a number) and the variable (as a character).

sum2 <- gather(sum1,-kc1$cluster,key=variable,value=value)
sum2

sum_total <- std1%>%
  summarize_all(funs(mean))
##summarize all variables by using the sum_total in order to be able to compare the means for each of these four different groups with the means for the sample as a whole.

sum_total <- gather(sum_total,key=variable,value=overall_mean)
##gives overall_mean based on the sum_total being added

pander(sum2 <- left_join(sum2,sum_total,by="variable"))
```


```{r Summary of Group Variables, results="asis"}
##Overall Summary of the Clusters Grouped by Variables

sum2 <- sum2%>%
  group_by(variable)%>%
  mutate(varmeans=mean(value))

pander(sum2)
```
